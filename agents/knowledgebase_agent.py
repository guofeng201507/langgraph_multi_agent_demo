from llm_router import summarize
from langsmith import traceable


@traceable(name="knowledgebase_agent")
def knowledgebase_agent(state):
    """
    Hybrid knowledgebase agent:
    - For general knowledge, use LLM to answer
    - For customer support topics, use internal knowledgebase (mock)
    """

    query = state.get("coordinator_response", {}).get("query", "").lower()

    # åˆ¤æ–­æ˜¯å¦å±äºå®¢æœæ”¯æŒé¢†åŸŸ
    support_keywords = ["refund", "delivery", "support", "invoice", "billing", "shipping", "order"]

    if any(keyword in query for keyword in support_keywords):
        # å†…éƒ¨çŸ¥è¯†åº“æ¨¡æ‹Ÿå“åº”ï¼ˆå¯æ¥ API æˆ–å‘é‡æ£€ç´¢ï¼‰
        if "refund" in query:
            answer = "ğŸ’° Our refund policy allows returns within 14 days of purchase. Contact support to initiate."
        elif "delivery" in query:
            answer = "ğŸ“¦ Deliveries typically arrive in 2â€“5 business days. Delays may occur during holidays."
        elif "support" in query:
            answer = "ğŸ§‘â€ğŸ’» You can reach our support team via chat or email (support@example.com)."
        else:
            answer = "ğŸ“˜ For customer-related topics, please check internal policies or support portal."
    else:
        # éå®¢æœé—®é¢˜ï¼Œä½¿ç”¨ LLM å›ç­”ï¼ˆè°ƒç”¨ summarize() æ¥ openai/qwen/deepseekï¼‰
        print("Not related with domain knowledge, using LLM own knowledge")
        prompt = f"You are a helpful AI assistant. Please answer the following question clearly:\n\nQ: {query}"
        try:
            answer = summarize(prompt, expect_json=False)["answer"]  # LLM è¿”å›æ ¼å¼åº”ä¸º {"answer": "..."}
        except:
            answer = "âš ï¸ Sorry, I couldn't generate a response. Please rephrase your question."

    return {
        "agent_outputs": {
            "knowledgebase_agent": answer
        }
    }
